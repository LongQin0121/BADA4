{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84be05a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 权重矩阵示例 ===\n",
      "Q矩阵（状态权重）:\n",
      "[[10.  0.]\n",
      " [ 0.  1.]]\n",
      "R矩阵（控制权重）:\n",
      "[[0.1]]\n",
      "目标状态: [5. 0.]\n",
      "\n",
      "--- 情况1：位置误差大 ---\n",
      "当前状态: [2.  0.1]\n",
      "状态误差: [-3.   0.1]\n",
      "状态成本: 45.01\n",
      "控制成本: 0.05\n",
      "总成本: 45.05\n",
      "\n",
      "--- 情况2：速度误差大 ---\n",
      "当前状态: [4.9 2. ]\n",
      "状态误差: [-0.1  2. ]\n",
      "状态成本: 2.05\n",
      "控制成本: 0.05\n",
      "总成本: 2.10\n",
      "\n",
      "=== 分析 ===\n",
      "位置误差3m的惩罚: 45.0\n",
      "速度误差2m/s的惩罚: 2.0\n",
      "位置误差的惩罚更重！\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def explain_weights():\n",
    "    \"\"\"解释权重矩阵如何影响成本计算\"\"\"\n",
    "    \n",
    "    # 定义权重\n",
    "    Q = np.array([[10.0, 0], [0, 1.0]])  # 状态权重\n",
    "    R = np.array([[0.1]])                # 控制权重\n",
    "    target = np.array([5.0, 0.0])        # 目标：位置5m，速度0m/s\n",
    "    \n",
    "    print(\"=== 权重矩阵示例 ===\")\n",
    "    print(f\"Q矩阵（状态权重）:\\n{Q}\")\n",
    "    print(f\"R矩阵（控制权重）:\\n{R}\")\n",
    "    print(f\"目标状态: {target}\")\n",
    "    \n",
    "    # 情况1：位置误差大\n",
    "    state1 = np.array([2.0, 0.1])  # 位置2m，速度0.1m/s\n",
    "    control1 = np.array([1.0])     # 加速度1m/s²\n",
    "    \n",
    "    state_error1 = state1 - target\n",
    "    state_cost1 = 0.5 * state_error1.T @ Q @ state_error1\n",
    "    control_cost1 = 0.5 * control1.T @ R @ control1\n",
    "    total_cost1 = state_cost1 + control_cost1\n",
    "    \n",
    "    print(f\"\\n--- 情况1：位置误差大 ---\")\n",
    "    print(f\"当前状态: {state1}\")\n",
    "    print(f\"状态误差: {state_error1}\")\n",
    "    print(f\"状态成本: {state_cost1:.2f}\")\n",
    "    print(f\"控制成本: {control_cost1:.2f}\")\n",
    "    print(f\"总成本: {total_cost1:.2f}\")\n",
    "    \n",
    "    # 情况2：速度误差大\n",
    "    state2 = np.array([4.9, 2.0])  # 位置4.9m，速度2m/s\n",
    "    control2 = np.array([1.0])     # 加速度1m/s²\n",
    "    \n",
    "    state_error2 = state2 - target\n",
    "    state_cost2 = 0.5 * state_error2.T @ Q @ state_error2\n",
    "    control_cost2 = 0.5 * control2.T @ R @ control2\n",
    "    total_cost2 = state_cost2 + control_cost2\n",
    "    \n",
    "    print(f\"\\n--- 情况2：速度误差大 ---\")\n",
    "    print(f\"当前状态: {state2}\")\n",
    "    print(f\"状态误差: {state_error2}\")\n",
    "    print(f\"状态成本: {state_cost2:.2f}\")\n",
    "    print(f\"控制成本: {control_cost2:.2f}\")\n",
    "    print(f\"总成本: {total_cost2:.2f}\")\n",
    "    \n",
    "    # 分析\n",
    "    print(f\"\\n=== 分析 ===\")\n",
    "    print(f\"位置误差3m的惩罚: {10.0 * 3**2 / 2:.1f}\")\n",
    "    print(f\"速度误差2m/s的惩罚: {1.0 * 2**2 / 2:.1f}\") \n",
    "    print(\"位置误差的惩罚更重！\")\n",
    "\n",
    "# 运行示例\n",
    "explain_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b445a7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 权重矩阵示例 ===\n",
      "Q矩阵（    状态权重）:\n",
      "[[10.  0.]\n",
      " [ 0.  1.]]\n",
      "R矩阵（控制权重）:\n",
      "[[0.1]]\n",
      "目标状态: [5. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"解释权重矩阵如何影响成本计算\"\"\"\n",
    "    \n",
    "    # 定义权重\n",
    "\"\"\"解释权重矩阵如何影响成本计算\"\"\"\n",
    "    \n",
    "# 定义权重\n",
    "Q = np.array([[10.0, 0], [0, 1.0]])  # 状态权重\n",
    "R = np.array([[0.1]])                # 控制权重\n",
    "target = np.array([5.0, 0.0])        # 目标：位置5m，速度0m/s\n",
    "\n",
    "print(\"=== 权重矩阵示例 ===\")\n",
    "print(f\"Q矩阵（    状态权重）:\\n{Q}\")\n",
    "print(f\"R矩阵（控制权重）:\\n{R}\")\n",
    "print(f\"目标状态: {target}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04fdf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 情况1：位置误差大 ---\n",
      "当前状态: [2.  0.1]\n",
      "状态误差: [-3.   0.1]\n",
      "状态成本: 45.01\n",
      "控制成本: 0.05\n",
      "总成本: 45.05\n"
     ]
    }
   ],
   "source": [
    "# 情况1：位置误差大\n",
    "state1 = np.array([2.0, 0.1])  # 位置2m，速度0.1m/s\n",
    "control1 = np.array([1.0])     # 加速度1m/s²\n",
    "\n",
    "state_error1 = state1 - target\n",
    "state_cost1 = 0.5 * state_error1.T @ Q @ state_error1\n",
    "control_cost1 = 0.5 * control1.T @ R @ control1\n",
    "total_cost1 = state_cost1 + control_cost1\n",
    "\n",
    "print(f\"\\n--- 情况1：位置误差大 ---\")\n",
    "print(f\"当前状态: {state1}\")\n",
    "print(f\"状态误差: {state_error1}\")\n",
    "print(f\"状态成本: {state_cost1:.2f}\")\n",
    "print(f\"控制成本: {control_cost1:.2f}\")\n",
    "print(f\"总成本: {total_cost1:.2f}\")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661b5b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵方式: 0.1478秒\n",
      "单独变量: 0.4724秒\n",
      "矩阵方式快 3.2倍\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def performance_comparison():\n",
    "    # 大规模测试\n",
    "    n_states = 100\n",
    "    n_tests = 10000\n",
    "    \n",
    "    # 生成测试数据\n",
    "    states = np.random.randn(n_tests, n_states)\n",
    "    targets = np.random.randn(n_tests, n_states)\n",
    "    Q = np.eye(n_states) * 10\n",
    "    \n",
    "    # 矩阵方式\n",
    "    start = time.time()\n",
    "    for i in range(n_tests):\n",
    "        error = states[i] - targets[i]\n",
    "        cost = 0.5 * error.T @ Q @ error\n",
    "    matrix_time = time.time() - start\n",
    "    \n",
    "    # 单独变量方式\n",
    "    start = time.time()\n",
    "    for i in range(n_tests):\n",
    "        cost = 0\n",
    "        for j in range(n_states):\n",
    "            error = states[i,j] - targets[i,j]\n",
    "            cost += 0.5 * error**2 * Q[j,j]\n",
    "    separate_time = time.time() - start\n",
    "    \n",
    "    print(f\"矩阵方式: {matrix_time:.4f}秒\")\n",
    "    print(f\"单独变量: {separate_time:.4f}秒\")\n",
    "    print(f\"矩阵方式快 {separate_time/matrix_time:.1f}倍\")\n",
    "performance_comparison()  # 矩阵通常快很多\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96d309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 综合性能对比测试 ===\n",
      "❌ GPU不可用: cudaErrorUnknown: unknown error\n",
      "\n",
      "--- 测试规模: 50维状态, 5000次计算 ---\n",
      "CPU矩阵运算:   0.0163秒\n",
      "CPU循环运算:   0.3736秒\n",
      "CPU向量化:     0.0070秒\n",
      "矩阵 vs 循环:  23.0x 加速\n",
      "向量化加速:    2.3x 加速\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 测试规模: 100维状态, 10000次计算 ---\n",
      "CPU矩阵运算:   0.5226秒\n",
      "CPU循环运算:   1.7716秒\n",
      "CPU向量化:     0.0030秒\n",
      "矩阵 vs 循环:  3.4x 加速\n",
      "向量化加速:    175.7x 加速\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 测试规模: 200维状态, 5000次计算 ---\n",
      "CPU矩阵运算:   0.2036秒\n",
      "CPU循环运算:   2.4831秒\n",
      "CPU向量化:     0.0055秒\n",
      "矩阵 vs 循环:  12.2x 加速\n",
      "向量化加速:    36.8x 加速\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== 内存使用和规模化测试 ===\n",
      "规模 100x100:\n",
      "  CPU内存: 0.0 MB\n",
      "  GPU内存: 不可用\n",
      "规模 500x500:\n",
      "  CPU内存: 1.0 MB\n",
      "  GPU内存: 不可用\n",
      "规模 1000x1000:\n",
      "  CPU内存: 3.8 MB\n",
      "  GPU内存: 不可用\n",
      "规模 2000x2000:\n",
      "  CPU内存: 15.3 MB\n",
      "  GPU内存: 不可用\n",
      "\n",
      "=== 高级GPU优化技术 ===\n",
      "高级GPU优化测试失败: cudaErrorUnknown: unknown error\n",
      "\n",
      "=== 实际MPC应用GPU加速演示 ===\n",
      "实际MPC演示失败: cudaErrorUnknown: unknown error\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def comprehensive_performance_test():\n",
    "    \"\"\"综合性能测试：CPU矩阵 vs CPU循环 vs GPU(如果可用)\"\"\"\n",
    "    \n",
    "    print(\"=== 综合性能对比测试 ===\")\n",
    "    \n",
    "    # 测试GPU可用性\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        # 尝试简单的GPU操作\n",
    "        test_array = cp.array([1, 2, 3])\n",
    "        _ = cp.sum(test_array)\n",
    "        GPU_AVAILABLE = True\n",
    "        print(\"✅ GPU可用 (CuPy)\")\n",
    "    except Exception as e:\n",
    "        GPU_AVAILABLE = False\n",
    "        print(f\"❌ GPU不可用: {e}\")\n",
    "    \n",
    "    # 测试配置\n",
    "    test_configs = [\n",
    "        (50, 5000),    # 中等规模\n",
    "        (100, 10000),  # 大规模\n",
    "        (200, 5000),   # 超大规模\n",
    "    ]\n",
    "    \n",
    "    for n_states, n_tests in test_configs:\n",
    "        print(f\"\\n--- 测试规模: {n_states}维状态, {n_tests}次计算 ---\")\n",
    "        \n",
    "        # 生成测试数据\n",
    "        np.random.seed(42)\n",
    "        states = np.random.randn(n_tests, n_states).astype(np.float32)\n",
    "        targets = np.random.randn(n_tests, n_states).astype(np.float32)\n",
    "        Q = np.eye(n_states, dtype=np.float32) * 10\n",
    "        \n",
    "        # 方法1: CPU矩阵运算\n",
    "        start_time = time.time()\n",
    "        cpu_costs_matrix = []\n",
    "        for i in range(n_tests):\n",
    "            error = states[i] - targets[i]\n",
    "            cost = 0.5 * error.T @ Q @ error\n",
    "            cpu_costs_matrix.append(cost)\n",
    "        cpu_matrix_time = time.time() - start_time\n",
    "        \n",
    "        # 方法2: CPU循环运算\n",
    "        start_time = time.time()\n",
    "        cpu_costs_loop = []\n",
    "        for i in range(n_tests):\n",
    "            cost = 0\n",
    "            for j in range(n_states):\n",
    "                error = states[i,j] - targets[i,j]\n",
    "                cost += 0.5 * error**2 * Q[j,j]\n",
    "            cpu_costs_loop.append(cost)\n",
    "        cpu_loop_time = time.time() - start_time\n",
    "        \n",
    "        # 方法3: CPU向量化（最优CPU方法）\n",
    "        start_time = time.time()\n",
    "        errors_batch = states - targets\n",
    "        cpu_costs_vectorized = 0.5 * np.sum(errors_batch * (errors_batch @ Q), axis=1)\n",
    "        cpu_vectorized_time = time.time() - start_time\n",
    "        \n",
    "        # 结果输出\n",
    "        print(f\"CPU矩阵运算:   {cpu_matrix_time:.4f}秒\")\n",
    "        print(f\"CPU循环运算:   {cpu_loop_time:.4f}秒\")\n",
    "        print(f\"CPU向量化:     {cpu_vectorized_time:.4f}秒\")\n",
    "        print(f\"矩阵 vs 循环:  {cpu_loop_time/cpu_matrix_time:.1f}x 加速\")\n",
    "        print(f\"向量化加速:    {cpu_matrix_time/cpu_vectorized_time:.1f}x 加速\")\n",
    "        \n",
    "        # GPU测试（如果可用）\n",
    "        if GPU_AVAILABLE:\n",
    "            try:\n",
    "                # 数据传输到GPU\n",
    "                states_gpu = cp.asarray(states)\n",
    "                targets_gpu = cp.asarray(targets)\n",
    "                Q_gpu = cp.asarray(Q)\n",
    "                \n",
    "                # 方法4: GPU逐个计算\n",
    "                start_time = time.time()\n",
    "                gpu_costs_individual = []\n",
    "                for i in range(n_tests):\n",
    "                    error = states_gpu[i] - targets_gpu[i]\n",
    "                    cost = 0.5 * error.T @ Q_gpu @ error\n",
    "                    gpu_costs_individual.append(float(cost))\n",
    "                gpu_individual_time = time.time() - start_time\n",
    "                \n",
    "                # 方法5: GPU批量计算（最优GPU方法）\n",
    "                cp.cuda.Stream.null.synchronize()  # 同步\n",
    "                start_time = time.time()\n",
    "                errors_gpu = states_gpu - targets_gpu\n",
    "                gpu_costs_batch = 0.5 * cp.sum(errors_gpu * (errors_gpu @ Q_gpu), axis=1)\n",
    "                cp.cuda.Stream.null.synchronize()\n",
    "                gpu_batch_time = time.time() - start_time\n",
    "                \n",
    "                # 方法6: GPU纯计算时间（数据已在GPU）\n",
    "                cp.cuda.Stream.null.synchronize()\n",
    "                start_time = time.time()\n",
    "                for _ in range(100):  # 多次运行取平均\n",
    "                    errors_gpu = states_gpu - targets_gpu\n",
    "                    _ = 0.5 * cp.sum(errors_gpu * (errors_gpu @ Q_gpu), axis=1)\n",
    "                cp.cuda.Stream.null.synchronize()\n",
    "                gpu_pure_time = (time.time() - start_time) / 100\n",
    "                \n",
    "                print(f\"GPU逐个计算:   {gpu_individual_time:.4f}秒\")\n",
    "                print(f\"GPU批量计算:   {gpu_batch_time:.4f}秒\")\n",
    "                print(f\"GPU纯计算:     {gpu_pure_time:.6f}秒\")\n",
    "                print(f\"GPU vs CPU矩阵: {cpu_matrix_time/gpu_batch_time:.1f}x 加速\")\n",
    "                print(f\"GPU vs CPU最优: {cpu_vectorized_time/gpu_batch_time:.1f}x 加速\")\n",
    "                \n",
    "                # 验证结果正确性\n",
    "                cpu_sum = np.sum(cpu_costs_vectorized)\n",
    "                gpu_sum = float(cp.sum(gpu_costs_batch))\n",
    "                print(f\"结果验证: CPU={cpu_sum:.2f}, GPU={gpu_sum:.2f}, 误差={abs(cpu_sum-gpu_sum):.6f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"GPU计算出错: {e}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "\n",
    "def memory_and_scaling_test():\n",
    "    \"\"\"内存使用和规模化测试\"\"\"\n",
    "    \n",
    "    print(\"\\n=== 内存使用和规模化测试 ===\")\n",
    "    \n",
    "    # 测试不同数据规模的内存使用\n",
    "    sizes = [100, 500, 1000, 2000]\n",
    "    \n",
    "    for size in sizes:\n",
    "        # CPU内存使用\n",
    "        cpu_data = np.random.randn(size, size).astype(np.float32)\n",
    "        cpu_memory_mb = cpu_data.nbytes / (1024**2)\n",
    "        \n",
    "        print(f\"规模 {size}x{size}:\")\n",
    "        print(f\"  CPU内存: {cpu_memory_mb:.1f} MB\")\n",
    "        \n",
    "        # GPU内存使用（如果可用）\n",
    "        try:\n",
    "            import cupy as cp\n",
    "            gpu_data = cp.asarray(cpu_data)\n",
    "            gpu_memory_mb = gpu_data.nbytes / (1024**2)\n",
    "            print(f\"  GPU内存: {gpu_memory_mb:.1f} MB\")\n",
    "            \n",
    "            # GPU内存池信息\n",
    "            mempool = cp.get_default_memory_pool()\n",
    "            print(f\"  GPU池使用: {mempool.used_bytes() / (1024**2):.1f} MB\")\n",
    "            \n",
    "            # 清理GPU内存\n",
    "            del gpu_data\n",
    "            mempool.free_all_blocks()\n",
    "            \n",
    "        except:\n",
    "            print(f\"  GPU内存: 不可用\")\n",
    "\n",
    "def advanced_gpu_optimization():\n",
    "    \"\"\"高级GPU优化技术演示\"\"\"\n",
    "    \n",
    "    try:\n",
    "        import cupy as cp\n",
    "        print(\"\\n=== 高级GPU优化技术 ===\")\n",
    "        \n",
    "        # 测试配置\n",
    "        n_states = 100\n",
    "        n_trajectories = 1000\n",
    "        horizon = 50\n",
    "        \n",
    "        # 生成测试数据\n",
    "        states_trajectories = cp.random.randn(n_trajectories, horizon, n_states)\n",
    "        target = cp.zeros(n_states)\n",
    "        Q = cp.eye(n_states) * 10.0\n",
    "        \n",
    "        # 方法1: 标准GPU计算\n",
    "        start_time = time.time()\n",
    "        costs_standard = []\n",
    "        for i in range(n_trajectories):\n",
    "            trajectory_cost = 0\n",
    "            for t in range(horizon):\n",
    "                error = states_trajectories[i, t] - target\n",
    "                cost = 0.5 * error.T @ Q @ error\n",
    "                trajectory_cost += cost\n",
    "            costs_standard.append(trajectory_cost)\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        standard_time = time.time() - start_time\n",
    "        \n",
    "        # 方法2: 高度优化的GPU批量计算\n",
    "        start_time = time.time()\n",
    "        # 一次性计算所有轨迹的所有时间步\n",
    "        errors_all = states_trajectories - target  # (n_trajectories, horizon, n_states)\n",
    "        # 批量计算二次型 \n",
    "        costs_batch = 0.5 * cp.sum(errors_all * cp.tensordot(errors_all, Q, axes=([2], [0])), axis=2)\n",
    "        trajectory_costs = cp.sum(costs_batch, axis=1)  # 沿时间轴求和\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        optimized_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"标准GPU计算:   {standard_time:.4f}秒\")\n",
    "        print(f\"优化GPU计算:   {optimized_time:.4f}秒\")\n",
    "        print(f\"优化加速比:    {standard_time/optimized_time:.1f}x\")\n",
    "        \n",
    "        # 验证结果\n",
    "        print(f\"结果验证: 标准={cp.sum(costs_standard):.2f}, 优化={cp.sum(trajectory_costs):.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"高级GPU优化测试失败: {e}\")\n",
    "\n",
    "def practical_mpc_gpu_demo():\n",
    "    \"\"\"实际MPC应用中的GPU加速演示\"\"\"\n",
    "    \n",
    "    print(\"\\n=== 实际MPC应用GPU加速演示 ===\")\n",
    "    \n",
    "    try:\n",
    "        import cupy as cp\n",
    "        \n",
    "        class HighPerformanceMPC:\n",
    "            def __init__(self, n_states, n_controls, horizon, use_gpu=True):\n",
    "                self.n_states = n_states\n",
    "                self.n_controls = n_controls\n",
    "                self.horizon = horizon\n",
    "                self.use_gpu = use_gpu\n",
    "                \n",
    "                if use_gpu:\n",
    "                    self.xp = cp\n",
    "                    self.Q = cp.eye(n_states, dtype=cp.float32) * 10.0\n",
    "                    self.R = cp.eye(n_controls, dtype=cp.float32) * 0.1\n",
    "                    self.target = cp.zeros(n_states, dtype=cp.float32)\n",
    "                else:\n",
    "                    self.xp = np\n",
    "                    self.Q = np.eye(n_states, dtype=np.float32) * 10.0\n",
    "                    self.R = np.eye(n_controls, dtype=np.float32) * 0.1\n",
    "                    self.target = np.zeros(n_states, dtype=np.float32)\n",
    "            \n",
    "            def evaluate_multiple_trajectories(self, states_batch, controls_batch):\n",
    "                \"\"\"批量评估多条轨迹的成本\"\"\"\n",
    "                n_candidates = states_batch.shape[0]\n",
    "                \n",
    "                # 状态成本计算\n",
    "                state_errors = states_batch - self.target  # (n_candidates, horizon+1, n_states)\n",
    "                state_costs = 0.5 * self.xp.sum(\n",
    "                    state_errors * (state_errors @ self.Q), axis=2\n",
    "                )  # (n_candidates, horizon+1)\n",
    "                \n",
    "                # 控制成本计算\n",
    "                control_costs = 0.5 * self.xp.sum(\n",
    "                    controls_batch * (controls_batch @ self.R), axis=2\n",
    "                )  # (n_candidates, horizon)\n",
    "                \n",
    "                # 总成本：状态成本 + 控制成本 + 终端成本\n",
    "                total_costs = (\n",
    "                    self.xp.sum(state_costs[:, :-1], axis=1) +  # 中间状态成本\n",
    "                    self.xp.sum(control_costs, axis=1) +        # 控制成本\n",
    "                    state_costs[:, -1]                          # 终端成本\n",
    "                )\n",
    "                \n",
    "                return total_costs\n",
    "        \n",
    "        # 性能测试\n",
    "        n_states, n_controls, horizon = 12, 4, 30\n",
    "        n_candidates = 1000\n",
    "        \n",
    "        # 生成候选轨迹\n",
    "        states_batch_cpu = np.random.randn(n_candidates, horizon+1, n_states).astype(np.float32)\n",
    "        controls_batch_cpu = np.random.randn(n_candidates, horizon, n_controls).astype(np.float32)\n",
    "        \n",
    "        # CPU测试\n",
    "        mpc_cpu = HighPerformanceMPC(n_states, n_controls, horizon, use_gpu=False)\n",
    "        start_time = time.time()\n",
    "        costs_cpu = mpc_cpu.evaluate_multiple_trajectories(states_batch_cpu, controls_batch_cpu)\n",
    "        cpu_time = time.time() - start_time\n",
    "        \n",
    "        # GPU测试\n",
    "        states_batch_gpu = cp.asarray(states_batch_cpu)\n",
    "        controls_batch_gpu = cp.asarray(controls_batch_cpu)\n",
    "        mpc_gpu = HighPerformanceMPC(n_states, n_controls, horizon, use_gpu=True)\n",
    "        \n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        start_time = time.time()\n",
    "        costs_gpu = mpc_gpu.evaluate_multiple_trajectories(states_batch_gpu, controls_batch_gpu)\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        gpu_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"MPC轨迹批量评估 ({n_candidates}条轨迹):\")\n",
    "        print(f\"CPU时间: {cpu_time:.4f}秒\")\n",
    "        print(f\"GPU时间: {gpu_time:.4f}秒\")\n",
    "        print(f\"GPU加速比: {cpu_time/gpu_time:.1f}x\")\n",
    "        \n",
    "        # 验证结果\n",
    "        costs_cpu_sum = np.sum(costs_cpu)\n",
    "        costs_gpu_sum = float(cp.sum(costs_gpu))\n",
    "        print(f\"结果验证: CPU={costs_cpu_sum:.2f}, GPU={costs_gpu_sum:.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"实际MPC演示失败: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 运行所有测试\n",
    "    comprehensive_performance_test()\n",
    "    memory_and_scaling_test()\n",
    "    advanced_gpu_optimization()\n",
    "    practical_mpc_gpu_demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c6cc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c198e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abe714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 向量化 vs 张量化性能对比 ===\n",
      "\n",
      "场景1: 批量矩阵-向量乘法\n",
      "\n",
      "批量大小: 100, 矩阵大小: 50x50\n",
      "  循环方式:     0.000210秒\n",
      "  向量化:       0.000070秒 (3.0x)\n",
      "  张量化:       0.000034秒 (6.2x)\n",
      "  优化张量:     0.000264秒 (0.8x)\n",
      "  误差检查: 向量化=4.19e+01, 张量化=0.00e+00, 优化=3.81e-06\n",
      "\n",
      "批量大小: 500, 矩阵大小: 50x50\n",
      "  循环方式:     0.000901秒\n",
      "  向量化:       0.000300秒 (3.0x)\n",
      "  张量化:       0.000194秒 (4.7x)\n",
      "  优化张量:     0.001339秒 (0.7x)\n",
      "  误差检查: 向量化=4.15e+01, 张量化=0.00e+00, 优化=7.63e-06\n",
      "\n",
      "批量大小: 1000, 矩阵大小: 50x50\n",
      "  循环方式:     0.001741秒\n",
      "  向量化:       0.000592秒 (2.9x)\n",
      "  张量化:       0.000404秒 (4.3x)\n",
      "  优化张量:     0.002753秒 (0.6x)\n",
      "  误差检查: 向量化=4.81e+01, 张量化=0.00e+00, 优化=7.63e-06\n",
      "\n",
      "批量大小: 2000, 矩阵大小: 50x50\n",
      "  循环方式:     0.003966秒\n",
      "  向量化:       0.001318秒 (3.0x)\n",
      "  张量化:       0.001082秒 (3.7x)\n",
      "  优化张量:     0.009218秒 (0.4x)\n",
      "  误差检查: 向量化=4.78e+01, 张量化=0.00e+00, 优化=5.72e-06\n",
      "\n",
      "场景2: 批量二次型计算\n",
      "\n",
      "不同维度下的二次型计算:\n",
      "\n",
      "维度: 10, 批量: 1000\n",
      "  循环方式:     0.001974秒\n",
      "  向量化:       0.000055秒 (36.0x)\n",
      "  张量化:       0.004968秒 (0.4x)\n",
      "  矩阵乘法:     0.000090秒 (21.9x)\n",
      "  误差: 向量化=9.16e-05, 张量化=1.83e-04, 矩阵=9.16e-05\n",
      "\n",
      "维度: 50, 批量: 1000\n",
      "  循环方式:     0.002608秒\n",
      "  向量化:       0.000744秒 (3.5x)\n",
      "  张量化:       0.004579秒 (0.6x)\n",
      "  矩阵乘法:     0.000160秒 (16.3x)\n",
      "  误差: 向量化=7.32e-04, 张量化=9.28e-03, 矩阵=7.32e-04\n",
      "\n",
      "维度: 100, 批量: 1000\n",
      "  循环方式:     0.025148秒\n",
      "  向量化:       0.001857秒 (13.5x)\n",
      "  张量化:       0.021813秒 (1.2x)\n",
      "  矩阵乘法:     0.001724秒 (14.6x)\n",
      "  误差: 向量化=2.93e-03, 张量化=4.39e-02, 矩阵=2.93e-03\n",
      "\n",
      "维度: 200, 批量: 1000\n",
      "  循环方式:     0.037291秒\n",
      "  向量化:       0.001065秒 (35.0x)\n",
      "  张量化:       0.095673秒 (0.4x)\n",
      "  矩阵乘法:     0.001883秒 (19.8x)\n",
      "  误差: 向量化=7.81e-03, 张量化=9.38e-02, 矩阵=7.81e-03\n",
      "\n",
      "场景3: 多维轨迹数据处理\n",
      "\n",
      "多维轨迹数据处理:\n",
      "数据形状: (500, 20, 10)\n",
      "  三重循环:     0.082594秒\n",
      "  部分向量化:   0.007042秒 (11.7x)\n",
      "  完全向量化:   0.000680秒 (121.4x)\n",
      "  张量化:       0.002839秒 (29.1x)\n",
      "  优化张量:     0.001205秒 (68.5x)\n",
      "  结果验证:\n",
      "    循环 vs 部分向量化: 4.20e-04\n",
      "    循环 vs 完全向量化: 4.20e-04\n",
      "    循环 vs 张量化:     4.20e-04\n",
      "    循环 vs 优化张量:   4.20e-04\n",
      "\n",
      "场景4: MPC实际应用对比\n",
      "\n",
      "MPC实际应用场景:\n",
      "\n",
      "配置: 6状态, 3控制, 20步, 100候选\n",
      "  循环方式:   0.033978秒\n",
      "  向量化:     0.000808秒 (42.1x)\n",
      "  张量化:     0.000720秒 (47.2x)\n",
      "  误差: 向量化=1.16e-04, 张量化=1.16e-04\n",
      "\n",
      "配置: 10状态, 4控制, 30步, 500候选\n",
      "  循环方式:   0.284031秒\n",
      "  向量化:     0.004085秒 (69.5x)\n",
      "  张量化:     0.010599秒 (26.8x)\n",
      "  误差: 向量化=3.57e-04, 张量化=3.57e-04\n",
      "\n",
      "配置: 15状态, 6控制, 50步, 200候选\n",
      "  循环方式:   0.121961秒\n",
      "  向量化:     0.001812秒 (67.3x)\n",
      "  张量化:     0.008567秒 (14.2x)\n",
      "  误差: 向量化=4.54e-04, 张量化=5.21e-04\n",
      "\n",
      "============================================================\n",
      "性能总结和建议:\n",
      "============================================================\n",
      "\n",
      "1. 向量化 vs 张量化的选择原则:\n",
      "   \n",
      "   • 低维数据 (< 100维): 向量化通常更快\n",
      "     - 内存访问模式更友好\n",
      "     - 缓存利用率更高\n",
      "     - 函数调用开销更小\n",
      "   \n",
      "   • 高维数据 (> 100维): 张量化可能更快\n",
      "     - 更好的并行化\n",
      "     - 减少中间结果存储\n",
      "     - 更高效的内存使用\n",
      "   \n",
      "   • 批量大小影响:\n",
      "     - 小批量: 向量化优势明显\n",
      "     - 大批量: 张量化优势显现\n",
      "\n",
      "2. 具体应用建议:\n",
      "   \n",
      "   • MPC轨迹评估: 向量化通常最优\n",
      "   • 大规模优化: 张量化更有优势\n",
      "   • 实时控制: 向量化延迟更低\n",
      "   • 离线训练: 张量化吞吐量更高\n",
      "\n",
      "3. 优化策略:\n",
      "   \n",
      "   • 避免不必要的数据复制\n",
      "   • 合理使用einsum和matmul\n",
      "   • 考虑内存布局(C-order vs F-order)\n",
      "   • 利用BLAS库的优化\n",
      "   \n",
      "4. GPU加速:\n",
      "   \n",
      "   • 张量化在GPU上通常更快\n",
      "   • 向量化在CPU上通常更快\n",
      "   • 数据传输成本需要考虑\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def vectorization_vs_tensorization_comparison():\n",
    "    \"\"\"向量化 vs 张量化性能对比\"\"\"\n",
    "    \n",
    "    print(\"=== 向量化 vs 张量化性能对比 ===\")\n",
    "    \n",
    "    # 测试场景1: 批量矩阵-向量乘法\n",
    "    print(\"\\n场景1: 批量矩阵-向量乘法\")\n",
    "    test_batch_matrix_vector()\n",
    "    \n",
    "    # 测试场景2: 批量二次型计算\n",
    "    print(\"\\n场景2: 批量二次型计算\")\n",
    "    test_batch_quadratic_form()\n",
    "    \n",
    "    # 测试场景3: 多维数据处理\n",
    "    print(\"\\n场景3: 多维轨迹数据处理\")\n",
    "    test_multidimensional_processing()\n",
    "    \n",
    "    # 测试场景4: MPC中的实际应用\n",
    "    print(\"\\n场景4: MPC实际应用对比\")\n",
    "    test_mpc_application()\n",
    "\n",
    "def test_batch_matrix_vector():\n",
    "    \"\"\"测试批量矩阵-向量乘法\"\"\"\n",
    "    \n",
    "    batch_sizes = [100, 500, 1000, 2000]\n",
    "    matrix_size = 50\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"\\n批量大小: {batch_size}, 矩阵大小: {matrix_size}x{matrix_size}\")\n",
    "        \n",
    "        # 生成测试数据\n",
    "        matrices = np.random.randn(batch_size, matrix_size, matrix_size).astype(np.float32)\n",
    "        vectors = np.random.randn(batch_size, matrix_size).astype(np.float32)\n",
    "        \n",
    "        # 方法1: 循环方式（基准）\n",
    "        start_time = time.time()\n",
    "        results_loop = []\n",
    "        for i in range(batch_size):\n",
    "            result = matrices[i] @ vectors[i]\n",
    "            results_loop.append(result)\n",
    "        results_loop = np.array(results_loop)\n",
    "        loop_time = time.time() - start_time\n",
    "        \n",
    "        # 方法2: 向量化方式\n",
    "        start_time = time.time()\n",
    "        # 使用einsum进行向量化计算\n",
    "        results_vectorized = np.einsum('bij,bi->bj', matrices, vectors)\n",
    "        vectorized_time = time.time() - start_time\n",
    "        \n",
    "        # 方法3: 张量化方式\n",
    "        start_time = time.time()\n",
    "        # 使用批量矩阵乘法\n",
    "        vectors_expanded = vectors[:, :, np.newaxis]  # (batch, matrix_size, 1)\n",
    "        results_tensorized = np.matmul(matrices, vectors_expanded).squeeze(-1)\n",
    "        tensorized_time = time.time() - start_time\n",
    "        \n",
    "        # 方法4: 高度优化的张量操作\n",
    "        start_time = time.time()\n",
    "        results_optimized = np.sum(matrices * vectors[:, np.newaxis, :], axis=2)\n",
    "        optimized_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"  循环方式:     {loop_time:.6f}秒\")\n",
    "        print(f\"  向量化:       {vectorized_time:.6f}秒 ({loop_time/vectorized_time:.1f}x)\")\n",
    "        print(f\"  张量化:       {tensorized_time:.6f}秒 ({loop_time/tensorized_time:.1f}x)\")\n",
    "        print(f\"  优化张量:     {optimized_time:.6f}秒 ({loop_time/optimized_time:.1f}x)\")\n",
    "        \n",
    "        # 验证结果正确性\n",
    "        error1 = np.max(np.abs(results_loop - results_vectorized))\n",
    "        error2 = np.max(np.abs(results_loop - results_tensorized))\n",
    "        error3 = np.max(np.abs(results_loop - results_optimized))\n",
    "        print(f\"  误差检查: 向量化={error1:.2e}, 张量化={error2:.2e}, 优化={error3:.2e}\")\n",
    "\n",
    "def test_batch_quadratic_form():\n",
    "    \"\"\"测试批量二次型计算 x^T Q x\"\"\"\n",
    "    \n",
    "    print(\"\\n不同维度下的二次型计算:\")\n",
    "    \n",
    "    dimensions = [10, 50, 100, 200]\n",
    "    batch_size = 1000\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        print(f\"\\n维度: {dim}, 批量: {batch_size}\")\n",
    "        \n",
    "        # 生成测试数据\n",
    "        X = np.random.randn(batch_size, dim).astype(np.float32)\n",
    "        Q = np.random.randn(dim, dim).astype(np.float32)\n",
    "        Q = Q.T @ Q  # 确保正定\n",
    "        \n",
    "        # 方法1: 循环计算\n",
    "        start_time = time.time()\n",
    "        results_loop = []\n",
    "        for i in range(batch_size):\n",
    "            result = X[i].T @ Q @ X[i]\n",
    "            results_loop.append(result)\n",
    "        results_loop = np.array(results_loop)\n",
    "        loop_time = time.time() - start_time\n",
    "        \n",
    "        # 方法2: 向量化计算\n",
    "        start_time = time.time()\n",
    "        results_vectorized = np.sum(X * (X @ Q), axis=1)\n",
    "        vectorized_time = time.time() - start_time\n",
    "        \n",
    "        # 方法3: 张量化计算\n",
    "        start_time = time.time()\n",
    "        results_tensorized = np.einsum('bi,ij,bj->b', X, Q, X)\n",
    "        tensorized_time = time.time() - start_time\n",
    "        \n",
    "        # 方法4: 矩阵乘法张量化\n",
    "        start_time = time.time()\n",
    "        XQ = X @ Q  # (batch_size, dim)\n",
    "        results_matmul = np.sum(X * XQ, axis=1)\n",
    "        matmul_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"  循环方式:     {loop_time:.6f}秒\")\n",
    "        print(f\"  向量化:       {vectorized_time:.6f}秒 ({loop_time/vectorized_time:.1f}x)\")\n",
    "        print(f\"  张量化:       {tensorized_time:.6f}秒 ({loop_time/tensorized_time:.1f}x)\")\n",
    "        print(f\"  矩阵乘法:     {matmul_time:.6f}秒 ({loop_time/matmul_time:.1f}x)\")\n",
    "        \n",
    "        # 验证结果\n",
    "        error1 = np.max(np.abs(results_loop - results_vectorized))\n",
    "        error2 = np.max(np.abs(results_loop - results_tensorized))\n",
    "        error3 = np.max(np.abs(results_loop - results_matmul))\n",
    "        print(f\"  误差: 向量化={error1:.2e}, 张量化={error2:.2e}, 矩阵={error3:.2e}\")\n",
    "\n",
    "def test_multidimensional_processing():\n",
    "    \"\"\"测试多维数据处理\"\"\"\n",
    "    \n",
    "    print(\"\\n多维轨迹数据处理:\")\n",
    "    \n",
    "    # 模拟MPC轨迹数据: (n_trajectories, horizon, n_states)\n",
    "    n_trajectories = 500\n",
    "    horizon = 20\n",
    "    n_states = 10\n",
    "    \n",
    "    # 生成测试数据\n",
    "    trajectories = np.random.randn(n_trajectories, horizon, n_states).astype(np.float32)\n",
    "    targets = np.random.randn(n_trajectories, horizon, n_states).astype(np.float32)\n",
    "    Q = np.eye(n_states, dtype=np.float32) * 10\n",
    "    \n",
    "    print(f\"数据形状: {trajectories.shape}\")\n",
    "    \n",
    "    # 方法1: 三重循环\n",
    "    start_time = time.time()\n",
    "    costs_loop = []\n",
    "    for i in range(n_trajectories):\n",
    "        trajectory_cost = 0\n",
    "        for t in range(horizon):\n",
    "            error = trajectories[i, t] - targets[i, t]\n",
    "            cost = 0.5 * error.T @ Q @ error\n",
    "            trajectory_cost += cost\n",
    "        costs_loop.append(trajectory_cost)\n",
    "    costs_loop = np.array(costs_loop)\n",
    "    loop_time = time.time() - start_time\n",
    "    \n",
    "    # 方法2: 部分向量化（轨迹内向量化）\n",
    "    start_time = time.time()\n",
    "    costs_partial_vec = []\n",
    "    for i in range(n_trajectories):\n",
    "        errors = trajectories[i] - targets[i]  # (horizon, n_states)\n",
    "        costs = 0.5 * np.sum(errors * (errors @ Q), axis=1)  # (horizon,)\n",
    "        trajectory_cost = np.sum(costs)\n",
    "        costs_partial_vec.append(trajectory_cost)\n",
    "    costs_partial_vec = np.array(costs_partial_vec)\n",
    "    partial_vec_time = time.time() - start_time\n",
    "    \n",
    "    # 方法3: 完全向量化\n",
    "    start_time = time.time()\n",
    "    errors_all = trajectories - targets  # (n_trajectories, horizon, n_states)\n",
    "    costs_all = 0.5 * np.sum(errors_all * (errors_all @ Q), axis=2)  # (n_trajectories, horizon)\n",
    "    costs_vectorized = np.sum(costs_all, axis=1)  # (n_trajectories,)\n",
    "    vectorized_time = time.time() - start_time\n",
    "    \n",
    "    # 方法4: 张量化计算\n",
    "    start_time = time.time()\n",
    "    errors_tensor = trajectories - targets\n",
    "    # 使用einsum进行高效张量计算\n",
    "    costs_tensor = 0.5 * np.einsum('ijk,kl,ijl->ij', errors_tensor, Q, errors_tensor)\n",
    "    costs_tensorized = np.sum(costs_tensor, axis=1)\n",
    "    tensorized_time = time.time() - start_time\n",
    "    \n",
    "    # 方法5: 优化的张量操作\n",
    "    start_time = time.time()\n",
    "    errors_opt = trajectories - targets\n",
    "    # 重塑为2D进行批量矩阵乘法\n",
    "    errors_2d = errors_opt.reshape(-1, n_states)  # (n_trajectories*horizon, n_states)\n",
    "    costs_2d = 0.5 * np.sum(errors_2d * (errors_2d @ Q), axis=1)\n",
    "    costs_optimized = costs_2d.reshape(n_trajectories, horizon).sum(axis=1)\n",
    "    optimized_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  三重循环:     {loop_time:.6f}秒\")\n",
    "    print(f\"  部分向量化:   {partial_vec_time:.6f}秒 ({loop_time/partial_vec_time:.1f}x)\")\n",
    "    print(f\"  完全向量化:   {vectorized_time:.6f}秒 ({loop_time/vectorized_time:.1f}x)\")\n",
    "    print(f\"  张量化:       {tensorized_time:.6f}秒 ({loop_time/tensorized_time:.1f}x)\")\n",
    "    print(f\"  优化张量:     {optimized_time:.6f}秒 ({loop_time/optimized_time:.1f}x)\")\n",
    "    \n",
    "    # 验证结果\n",
    "    print(f\"  结果验证:\")\n",
    "    print(f\"    循环 vs 部分向量化: {np.max(np.abs(costs_loop - costs_partial_vec)):.2e}\")\n",
    "    print(f\"    循环 vs 完全向量化: {np.max(np.abs(costs_loop - costs_vectorized)):.2e}\")\n",
    "    print(f\"    循环 vs 张量化:     {np.max(np.abs(costs_loop - costs_tensorized)):.2e}\")\n",
    "    print(f\"    循环 vs 优化张量:   {np.max(np.abs(costs_loop - costs_optimized)):.2e}\")\n",
    "\n",
    "def test_mpc_application():\n",
    "    \"\"\"MPC实际应用中的性能对比\"\"\"\n",
    "    \n",
    "    print(\"\\nMPC实际应用场景:\")\n",
    "    \n",
    "    class MPCPerformanceTest:\n",
    "        def __init__(self, n_states, n_controls, horizon):\n",
    "            self.n_states = n_states\n",
    "            self.n_controls = n_controls\n",
    "            self.horizon = horizon\n",
    "            self.Q = np.eye(n_states, dtype=np.float32) * 10\n",
    "            self.R = np.eye(n_controls, dtype=np.float32) * 0.1\n",
    "            self.target = np.zeros(n_states, dtype=np.float32)\n",
    "        \n",
    "        def evaluate_trajectories_loop(self, states_batch, controls_batch):\n",
    "            \"\"\"循环方式评估轨迹\"\"\"\n",
    "            n_candidates = states_batch.shape[0]\n",
    "            costs = []\n",
    "            \n",
    "            for i in range(n_candidates):\n",
    "                total_cost = 0\n",
    "                for t in range(self.horizon):\n",
    "                    # 状态成本\n",
    "                    state_error = states_batch[i, t] - self.target\n",
    "                    state_cost = 0.5 * state_error.T @ self.Q @ state_error\n",
    "                    \n",
    "                    # 控制成本\n",
    "                    control_cost = 0.5 * controls_batch[i, t].T @ self.R @ controls_batch[i, t]\n",
    "                    \n",
    "                    total_cost += state_cost + control_cost\n",
    "                \n",
    "                # 终端成本\n",
    "                final_error = states_batch[i, -1] - self.target\n",
    "                total_cost += 0.5 * final_error.T @ self.Q @ final_error\n",
    "                costs.append(total_cost)\n",
    "            \n",
    "            return np.array(costs)\n",
    "        \n",
    "        def evaluate_trajectories_vectorized(self, states_batch, controls_batch):\n",
    "            \"\"\"向量化方式评估轨迹\"\"\"\n",
    "            # 状态成本\n",
    "            state_errors = states_batch - self.target\n",
    "            state_costs = 0.5 * np.sum(state_errors * (state_errors @ self.Q), axis=2)\n",
    "            \n",
    "            # 控制成本\n",
    "            control_costs = 0.5 * np.sum(controls_batch * (controls_batch @ self.R), axis=2)\n",
    "            \n",
    "            # 总成本\n",
    "            total_costs = (\n",
    "                np.sum(state_costs[:, :-1], axis=1) +  # 中间状态成本\n",
    "                np.sum(control_costs, axis=1) +        # 控制成本\n",
    "                state_costs[:, -1]                     # 终端成本\n",
    "            )\n",
    "            \n",
    "            return total_costs\n",
    "        \n",
    "        def evaluate_trajectories_tensorized(self, states_batch, controls_batch):\n",
    "            \"\"\"张量化方式评估轨迹\"\"\"\n",
    "            # 使用einsum进行张量计算\n",
    "            state_errors = states_batch - self.target\n",
    "            \n",
    "            # 状态成本张量计算\n",
    "            state_costs = 0.5 * np.einsum('ijk,kl,ijl->ij', state_errors, self.Q, state_errors)\n",
    "            \n",
    "            # 控制成本张量计算\n",
    "            control_costs = 0.5 * np.einsum('ijk,kl,ijl->ij', controls_batch, self.R, controls_batch)\n",
    "            \n",
    "            # 总成本\n",
    "            total_costs = (\n",
    "                np.sum(state_costs[:, :-1], axis=1) +\n",
    "                np.sum(control_costs, axis=1) +\n",
    "                state_costs[:, -1]\n",
    "            )\n",
    "            \n",
    "            return total_costs\n",
    "    \n",
    "    # 测试不同规模\n",
    "    test_configs = [\n",
    "        (6, 3, 20, 100),   # 小规模\n",
    "        (10, 4, 30, 500),  # 中规模\n",
    "        (15, 6, 50, 200),  # 大规模\n",
    "    ]\n",
    "    \n",
    "    for n_states, n_controls, horizon, n_candidates in test_configs:\n",
    "        print(f\"\\n配置: {n_states}状态, {n_controls}控制, {horizon}步, {n_candidates}候选\")\n",
    "        \n",
    "        mpc = MPCPerformanceTest(n_states, n_controls, horizon)\n",
    "        \n",
    "        # 生成测试数据\n",
    "        states_batch = np.random.randn(n_candidates, horizon+1, n_states).astype(np.float32)\n",
    "        controls_batch = np.random.randn(n_candidates, horizon, n_controls).astype(np.float32)\n",
    "        \n",
    "        # 循环方式\n",
    "        start_time = time.time()\n",
    "        costs_loop = mpc.evaluate_trajectories_loop(states_batch, controls_batch)\n",
    "        loop_time = time.time() - start_time\n",
    "        \n",
    "        # 向量化方式\n",
    "        start_time = time.time()\n",
    "        costs_vectorized = mpc.evaluate_trajectories_vectorized(states_batch, controls_batch)\n",
    "        vectorized_time = time.time() - start_time\n",
    "        \n",
    "        # 张量化方式\n",
    "        start_time = time.time()\n",
    "        costs_tensorized = mpc.evaluate_trajectories_tensorized(states_batch, controls_batch)\n",
    "        tensorized_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"  循环方式:   {loop_time:.6f}秒\")\n",
    "        print(f\"  向量化:     {vectorized_time:.6f}秒 ({loop_time/vectorized_time:.1f}x)\")\n",
    "        print(f\"  张量化:     {tensorized_time:.6f}秒 ({loop_time/tensorized_time:.1f}x)\")\n",
    "        \n",
    "        # 验证结果\n",
    "        error1 = np.max(np.abs(costs_loop - costs_vectorized))\n",
    "        error2 = np.max(np.abs(costs_loop - costs_tensorized))\n",
    "        print(f\"  误差: 向量化={error1:.2e}, 张量化={error2:.2e}\")\n",
    "\n",
    "def performance_summary():\n",
    "    \"\"\"性能总结和建议\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"性能总结和建议:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\"\"\n",
    "1. 向量化 vs 张量化的选择原则:\n",
    "   \n",
    "   • 低维数据 (< 100维): 向量化通常更快\n",
    "     - 内存访问模式更友好\n",
    "     - 缓存利用率更高\n",
    "     - 函数调用开销更小\n",
    "   \n",
    "   • 高维数据 (> 100维): 张量化可能更快\n",
    "     - 更好的并行化\n",
    "     - 减少中间结果存储\n",
    "     - 更高效的内存使用\n",
    "   \n",
    "   • 批量大小影响:\n",
    "     - 小批量: 向量化优势明显\n",
    "     - 大批量: 张量化优势显现\n",
    "\n",
    "2. 具体应用建议:\n",
    "   \n",
    "   • MPC轨迹评估: 向量化通常最优\n",
    "   • 大规模优化: 张量化更有优势\n",
    "   • 实时控制: 向量化延迟更低\n",
    "   • 离线训练: 张量化吞吐量更高\n",
    "\n",
    "3. 优化策略:\n",
    "   \n",
    "   • 避免不必要的数据复制\n",
    "   • 合理使用einsum和matmul\n",
    "   • 考虑内存布局(C-order vs F-order)\n",
    "   • 利用BLAS库的优化\n",
    "   \n",
    "4. GPU加速:\n",
    "   \n",
    "   • 张量化在GPU上通常更快\n",
    "   • 向量化在CPU上通常更快\n",
    "   • 数据传输成本需要考虑\n",
    "    \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vectorization_vs_tensorization_comparison()\n",
    "    performance_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55993192",
   "metadata": {},
   "source": [
    "总结：向量化 vs 张量化的性能差异\n",
    "\n",
    "向量化更快的情况：\n",
    "\n",
    "低维数据（< 100维）\n",
    "\n",
    "小批量处理\n",
    "\n",
    "CPU计算\n",
    "\n",
    "需要低延迟的实时应用\n",
    "\n",
    "张量化更快的情况：\n",
    "\n",
    "高维数据（> 100维）\n",
    "\n",
    "大批量处理\n",
    "\n",
    "GPU计算\n",
    "\n",
    "复杂的多维运算\n",
    "\n",
    "实际经验：\n",
    "\n",
    "在MPC应用中，向量化通常是最佳选择\n",
    "\n",
    "张量化在深度学习和大规模数值计算中更有优势\n",
    "\n",
    "具体性能取决于数据形状、硬件和具体操作"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
